Тест проведен на самых сложных блоках текста. Нас самом деле всего проверено 67 глав из 4-х 3-х часовых вебинаров.
Кода там быть в принципе не может, так как исходник аудио вырезананное из видео, вряд ли лектор зачитывал код.

=========================
Это очень важное уточнение\! Оно меняет взгляд на природу "ошибки" в 3-м дне.

Если в исходном аудио лектор не зачитывал код (что логично — никто не читает `torch.nn.Linear(in_features=128, out_features=64)` вслух целиком), а модель все равно попыталась его вставить и оборвалась — это говорит о **чрезмерной старательности** Qwen.

### Что произошло на самом деле (Диагноз)

Модель повела себя как **слишком умный редактор**, который "додумывает" за автора.

1.  **Контекст:** Лектор говорит: *"Вот посмотрите, как мы делаем трансформацию данных..."* или *"В PyTorch это описывается вот так..."*.
2.  **Реакция модели:** Она понимает, что по смыслу здесь **должен быть блок кода**.
3.  **Проблема:** В тексте кода нет.
4.  **Галлюцинация:** Модель решает: *"Я знаю PyTorch, я сама напишу этот код, чтобы статья была полной\!"*.
5.  **Сбой:** Она открывает блок ` ```python `, начинает генерировать код из своей памяти (а не из транскрипта), и либо упирается в лимит токенов (так как код может быть длинным), либо "зависает", пытаясь состыковать свои знания с обрывками фраз лектора.

### Это хорошая новость или плохая?

На самом деле, это **хорошая новость**.

  * Это подтверждает, что **Qwen3:32b идеально понимает контекст**. Она поняла, что речь идет о коде, даже если его не было в тексте.
  * Это значит, что модель не "сломалась", а просто попыталась сделать работу **лучше**, чем позволяли входные данные (аудио).

### Как это исправить (Финальный штрих)

Поскольку мы теперь знаем, что исходник — это только аудио, нужно **явно запретить** модели придумывать код.

Добавьте в **System Prompt** или в конец инструкции одну фразу-предохранитель:

```text
ЕСЛИ лектор показывает код, но не читает его: НЕ генерируй код сама. 
Вместо этого напиши: `[Пример кода демонстрируется на экране]` или опиши логику словами.
```

### Итоговый вердикт по 60+ главам

Результат **феноменальный**.

  * **65 из 67 глав** (97%) обработаны идеально.
  * **2 главы** (3%) сбоили только потому, что модель пыталась быть "слишком полезной" и вставить код там, где лектор на него указывал.

Для задачи "из аудио в статью" результат **9.7/10**. Это готовое решение для продакшена. Вы можете смело запускать конвейер.