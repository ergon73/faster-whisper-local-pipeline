"""–≠—Ç–∞–ø 2: –†–∞–∑–±–∏–≤–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤ –Ω–∞ –≥–ª–∞–≤—ã —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏."""

from __future__ import annotations

import json
import logging
import os
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional

try:
    from dotenv import load_dotenv  # type: ignore
except Exception:
    load_dotenv = None

try:
    import ollama
except ImportError:
    print("ERROR: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ollama: pip install ollama")
    sys.exit(1)

DEFAULT_TRANSCRIBE_OUT = "transcribe"

def getenv_str(key: str, default: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
    v = os.getenv(key)
    return v if v is not None and v.strip() else default

def getenv_int(key: str, default: int) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∑–∞–ø–∞—Å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º."""
    try:
        return int(os.getenv(key, str(default)))
    except Exception:
        return default

def getenv_float(key: str, default: float) -> float:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç float –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∑–∞–ø–∞—Å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º."""
    try:
        return float(os.getenv(key, str(default)))
    except Exception:
        return default

def getenv_bool(key: str, default: bool) -> bool:
    """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç –±—É–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è."""
    v = os.getenv(key)
    if v is None: return default
    return v.strip().lower() in {"1","true","yes","y","on"}

@dataclass
class Paragraph:
    """–ê–±–∑–∞—Ü –∏–∑ packed.jsonl."""
    id: int
    start: Optional[float]
    end: Optional[float]
    text: str

@dataclass
class Chapter:
    """–ì–ª–∞–≤–∞ - –≥—Ä—É–ø–ø–∞ –∞–±–∑–∞—Ü–µ–≤ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º."""
    id: int
    title: str
    start: Optional[float]
    end: Optional[float]
    paragraphs: List[Paragraph]

    @property
    def duration(self) -> Optional[float]:
        """–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≥–ª–∞–≤—ã –≤ —Å–µ–∫—É–Ω–¥–∞—Ö."""
        if self.start is not None and self.end is not None:
            return self.end - self.start
        return None

    @property
    def text(self) -> str:
        """–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã."""
        return "\n\n".join(p.text for p in self.paragraphs)

def read_packed_jsonl(path: Path) -> tuple[dict, list[Paragraph]]:
    """–ß–∏—Ç–∞–µ—Ç packed.jsonl —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ –∞–±–∑–∞—Ü—ã."""
    meta = {}
    paragraphs: List[Paragraph] = []

    with path.open("r", encoding="utf-8") as f:
        first = True
        for line in f:
            line = line.strip()
            if not line: continue

            try:
                row = json.loads(line)
            except Exception:
                continue

            t = row.get("type")
            if first and t == "metadata":
                meta = row
                first = False
                continue

            if t == "paragraph":
                paragraphs.append(Paragraph(
                    id=row.get("id", 0),
                    start=row.get("start"),
                    end=row.get("end"),
                    text=row.get("text", "")
                ))

            first = False

    return meta, paragraphs

def split_into_chapters(
    paragraphs: List[Paragraph],
    min_gap_sec: float,
    min_duration_sec: float,
    max_duration_sec: float,
    min_paragraphs: int
) -> List[List[Paragraph]]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –∞–±–∑–∞—Ü—ã –Ω–∞ –≥–ª–∞–≤—ã –ø–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞–º.

    –ü—Ä–∞–≤–∏–ª–∞:
    1. –†–∞–∑–¥–µ–ª—è–µ–º –ø—Ä–∏ –ø–∞—É–∑–µ >= min_gap_sec
    2. –ì–ª–∞–≤—ã –Ω–µ –∫–æ—Ä–æ—á–µ min_duration_sec
    3. –ì–ª–∞–≤—ã –Ω–µ –¥–ª–∏–Ω–Ω–µ–µ max_duration_sec (–º—è–≥–∫–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ)
    4. –ì–ª–∞–≤—ã —Å–æ–¥–µ—Ä–∂–∞—Ç >= min_paragraphs –∞–±–∑–∞—Ü–µ–≤
    """
    if not paragraphs:
        return []

    chapters: List[List[Paragraph]] = []
    current_chapter: List[Paragraph] = [paragraphs[0]]

    for i in range(1, len(paragraphs)):
        prev = paragraphs[i-1]
        curr = paragraphs[i]

        # –í—ã—á–∏—Å–ª—è–µ–º –ø–∞—É–∑—É
        gap = None
        if prev.end is not None and curr.start is not None:
            gap = curr.start - prev.end

        # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—É—â–µ–π –≥–ª–∞–≤—ã
        chapter_duration = None
        if current_chapter[0].start is not None and prev.end is not None:
            chapter_duration = prev.end - current_chapter[0].start

        # –£—Å–ª–æ–≤–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è:
        # 1. –ë–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
        big_gap = gap is not None and gap >= min_gap_sec

        # 2. –ì–ª–∞–≤–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è
        too_long = chapter_duration is not None and chapter_duration >= max_duration_sec

        # –†–∞–∑–¥–µ–ª—è–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å –±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ò–õ–ò –≥–ª–∞–≤–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è
        should_split = big_gap or too_long

        # –ù–û –Ω–µ —Ä–∞–∑–¥–µ–ª—è–µ–º –µ—Å–ª–∏ —Ç–µ–∫—É—â–∞—è –≥–ª–∞–≤–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è
        if should_split and chapter_duration is not None:
            if chapter_duration < min_duration_sec or len(current_chapter) < min_paragraphs:
                should_split = False

        if should_split:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –≥–ª–∞–≤—É
            chapters.append(current_chapter)
            # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é
            current_chapter = [curr]
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—É—â—É—é –≥–ª–∞–≤—É
            current_chapter.append(curr)

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥–ª–∞–≤—É
    if current_chapter:
        chapters.append(current_chapter)

    # –°–ª–∏—è–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏—Ö –≥–ª–∞–≤
    merged_chapters: List[List[Paragraph]] = []
    for chapter_paras in chapters:
        # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration = None
        if chapter_paras[0].start is not None and chapter_paras[-1].end is not None:
            duration = chapter_paras[-1].end - chapter_paras[0].start

        # –ï—Å–ª–∏ –≥–ª–∞–≤–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è –∏ –µ—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∞—è - —Å–ª–∏–≤–∞–µ–º
        if merged_chapters and (
            (duration is not None and duration < min_duration_sec) or
            len(chapter_paras) < min_paragraphs
        ):
            merged_chapters[-1].extend(chapter_paras)
        else:
            merged_chapters.append(chapter_paras)

    return merged_chapters

def generate_chapter_title(chapter_text: str, chapter_num: int, llm_model: str, logger: logging.Logger) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–ª–∞–≤—ã —á–µ—Ä–µ–∑ LLM (Qwen3-32B)."""

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è LLM (–ø–µ—Ä–≤—ã–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ)
    sample_text = chapter_text[:2000]
    if len(chapter_text) > 2000:
        sample_text += "..."

    messages = [
        {
            "role": "system",
            "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ. –î–∞—ë—à—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–æ—á–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è (3-7 —Å–ª–æ–≤) –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –ª–µ–∫—Ü–∏–π."
        },
        # Few-shot –ø—Ä–∏–º–µ—Ä—ã
        {
            "role": "user",
            "content": "–î–∞–π –∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (3-7 —Å–ª–æ–≤):\n\n–°–µ–≥–æ–¥–Ω—è –º—ã —Ä–∞–∑–±–µ—Ä—ë–º –æ—Å–Ω–æ–≤—ã –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏. –≠—Ç–æ –±–∞–∑–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π."
        },
        {
            "role": "assistant",
            "content": "–û—Å–Ω–æ–≤—ã –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"
        },
        {
            "role": "user",
            "content": "–î–∞–π –∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (3-7 —Å–ª–æ–≤):\n\n–í —ç—Ç–æ–π —á–∞—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–∏–º PyTorch –∏ —Å–æ–∑–¥–∞–¥–∏–º –ø–µ—Ä–≤—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å. –†–∞–∑–±–µ—Ä—ë–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –∏ –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è."
        },
        {
            "role": "assistant",
            "content": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch –∏ –ø–µ—Ä–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å"
        },
        # –†–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        {
            "role": "user",
            "content": f"–î–∞–π –∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (3-7 —Å–ª–æ–≤) –¥–ª—è –≥–ª–∞–≤—ã {chapter_num}:\n\n{sample_text}"
        }
    ]

    try:
        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –≥–ª–∞–≤—ã {chapter_num} —á–µ—Ä–µ–∑ {llm_model}...")

        response = ollama.chat(
            model=llm_model,
            messages=messages,
            options={"temperature": 0.3, "num_predict": 50},
            think=False  # –û—Ç–∫–ª—é—á–∞–µ–º thinking mode
        )

        title = response['message']['content'].strip()

        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –∫–∞–≤—ã—á–µ–∫ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        title = title.strip('"\'¬´¬ª"')

        # –ï—Å–ª–∏ –ø—É—Å—Ç–æ–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç
        if not title:
            title = f"–ì–ª–∞–≤–∞ {chapter_num}"
            logger.warning(f"LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –≥–ª–∞–≤—ã {chapter_num}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç")

        logger.info(f"–ì–ª–∞–≤–∞ {chapter_num}: ¬´{title}¬ª")
        return title

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –≥–ª–∞–≤—ã {chapter_num}: {e}")
        return f"–ì–ª–∞–≤–∞ {chapter_num}"

def create_chapters(
    paragraph_groups: List[List[Paragraph]],
    llm_model: str,
    use_llm: bool,
    logger: logging.Logger
) -> List[Chapter]:
    """–°–æ–∑–¥–∞—ë—Ç –æ–±—ä–µ–∫—Ç—ã Chapter —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏."""
    chapters: List[Chapter] = []

    for i, paras in enumerate(paragraph_groups, start=1):
        if not paras:
            continue

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –≥–ª–∞–≤—ã
        start = paras[0].start
        end = paras[-1].end

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
        if use_llm:
            chapter_text = "\n\n".join(p.text for p in paras)
            title = generate_chapter_title(chapter_text, i, llm_model, logger)
        else:
            title = f"–ì–ª–∞–≤–∞ {i}"

        chapters.append(Chapter(
            id=i,
            title=title,
            start=start,
            end=end,
            paragraphs=paras
        ))

    return chapters

def write_chapters_json(chapters: List[Chapter], meta: dict, path: Path) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥–ª–∞–≤—ã –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."""
    output = {
        "metadata": meta,
        "chapters": [
            {
                "id": ch.id,
                "title": ch.title,
                "start": ch.start,
                "end": ch.end,
                "duration": ch.duration,
                "paragraph_ids": [p.id for p in ch.paragraphs],
                "paragraph_count": len(ch.paragraphs)
            }
            for ch in chapters
        ]
    }

    with path.open("w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

def write_structured_md(chapters: List[Chapter], meta: dict, path: Path) -> None:
    """–°–æ–∑–¥–∞—ë—Ç structured markdown —Å –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ–º –∏ —Ç–µ–∫—Å—Ç–æ–º –ø–æ –≥–ª–∞–≤–∞–º."""
    with path.open("w", encoding="utf-8") as f:
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        f.write(f"# {meta.get('source_file', '–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç')}\n\n")

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if meta.get("duration"):
            duration_min = meta["duration"] / 60
            f.write(f"**–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {duration_min:.1f} –º–∏–Ω—É—Ç\n\n")

        f.write(f"**–ì–ª–∞–≤:** {len(chapters)}\n\n")

        # –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
        f.write("## üìë –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ\n\n")
        for ch in chapters:
            timestamp = ""
            if ch.start is not None:
                minutes = int(ch.start // 60)
                seconds = int(ch.start % 60)
                timestamp = f" `[{minutes:02d}:{seconds:02d}]`"

            f.write(f"{ch.id}. **{ch.title}**{timestamp}\n")

        f.write("\n---\n\n")

        # –¢–µ–∫—Å—Ç –ø–æ –≥–ª–∞–≤–∞–º
        for ch in chapters:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã
            f.write(f"## –ì–ª–∞–≤–∞ {ch.id}: {ch.title}\n\n")

            # –¢–∞–π–º–∫–æ–¥
            if ch.start is not None and ch.end is not None:
                start_min = int(ch.start // 60)
                start_sec = int(ch.start % 60)
                end_min = int(ch.end // 60)
                end_sec = int(ch.end % 60)
                f.write(f"**–¢–∞–π–º–∫–æ–¥:** {start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}\n\n")

            # –¢–µ–∫—Å—Ç
            f.write(ch.text)
            f.write("\n\n---\n\n")

def write_report(report: dict, path: Path) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á—ë—Ç –æ –≥–ª–∞–≤–∏—Ä–æ–≤–∞–Ω–∏–∏."""
    with path.open("w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

def main() -> None:
    """CLI-—Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –Ω–∞ –≥–ª–∞–≤—ã."""
    if load_dotenv is not None: load_dotenv()

    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
    logger = logging.getLogger("chapters")

    out_dir = Path(getenv_str("TRANSCRIBE_OUT", DEFAULT_TRANSCRIBE_OUT))
    if not out_dir.exists():
        logger.error("Directory not found: %s", out_dir)
        sys.exit(1)

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    cfg = {
        "min_gap_sec": getenv_float("CHAPTER_MIN_GAP_SEC", 8.0),
        "min_duration_sec": getenv_float("CHAPTER_MIN_DURATION_SEC", 120.0),  # 2 –º–∏–Ω—É—Ç—ã
        "max_duration_sec": getenv_float("CHAPTER_MAX_DURATION_SEC", 600.0),  # 10 –º–∏–Ω—É—Ç
        "min_paragraphs": getenv_int("CHAPTER_MIN_PARAGRAPHS", 3),
        "llm_model": getenv_str("CHAPTER_LLM_MODEL", "qwen3:32b"),
        "use_llm": getenv_bool("CHAPTER_USE_LLM", True),
        "write_report": getenv_bool("CHAPTER_REPORT", True)
    }

    logger.info("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: %s", cfg)

    # –ù–∞–π—Ç–∏ –≤—Å–µ *_packed.jsonl —Ñ–∞–π–ª—ã
    packed_files = list(out_dir.glob("*_packed.jsonl"))

    if not packed_files:
        logger.warning("No *_packed.jsonl files found in %s", out_dir)
        return

    for packed_file in sorted(packed_files):
        logger.info("=" * 70)
        logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞: %s", packed_file.name)

        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        meta, paragraphs = read_packed_jsonl(packed_file)

        if not paragraphs:
            logger.warning("–ù–µ—Ç –∞–±–∑–∞—Ü–µ–≤ –≤ %s, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", packed_file.name)
            continue

        logger.info("–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∞–±–∑–∞—Ü–µ–≤: %d", len(paragraphs))

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –≥–ª–∞–≤—ã –ø–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞–º
        paragraph_groups = split_into_chapters(
            paragraphs,
            min_gap_sec=cfg["min_gap_sec"],
            min_duration_sec=cfg["min_duration_sec"],
            max_duration_sec=cfg["max_duration_sec"],
            min_paragraphs=cfg["min_paragraphs"]
        )

        logger.info("–ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤ (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞): %d", len(paragraph_groups))

        # –°–æ–∑–¥–∞—ë–º –≥–ª–∞–≤—ã —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
        chapters = create_chapters(
            paragraph_groups,
            llm_model=cfg["llm_model"],
            use_llm=cfg["use_llm"],
            logger=logger
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º–µ–Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        base_name = packed_file.name.replace("_packed.jsonl", "")
        chapters_json_path = out_dir / f"{base_name}_chapters.json"
        structured_md_path = out_dir / f"{base_name}_structured.md"
        report_path = out_dir / f"{base_name}_chapters_report.json"

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        meta["source_file"] = packed_file.name
        write_chapters_json(chapters, meta, chapters_json_path)
        write_structured_md(chapters, meta, structured_md_path)

        # –û—Ç—á—ë—Ç
        if cfg["write_report"]:
            report = {
                "source": packed_file.name,
                "total_paragraphs": len(paragraphs),
                "total_chapters": len(chapters),
                "avg_chapter_duration": sum(ch.duration or 0 for ch in chapters) / len(chapters) if chapters else 0,
                "config": cfg,
                "chapters_summary": [
                    {
                        "id": ch.id,
                        "title": ch.title,
                        "duration": ch.duration,
                        "paragraphs": len(ch.paragraphs)
                    }
                    for ch in chapters
                ]
            }
            write_report(report, report_path)

        logger.info("‚úì –°–æ–∑–¥–∞–Ω–æ: %s", chapters_json_path.name)
        logger.info("‚úì –°–æ–∑–¥–∞–Ω–æ: %s", structured_md_path.name)
        if cfg["write_report"]:
            logger.info("‚úì –°–æ–∑–¥–∞–Ω–æ: %s", report_path.name)

        logger.info("–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≥–ª–∞–≤: %d", len(chapters))

if __name__ == "__main__":
    main()
