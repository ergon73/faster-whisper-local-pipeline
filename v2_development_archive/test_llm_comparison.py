"""–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM-–º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤."""

import json
import time
from pathlib import Path
from datetime import datetime

try:
    import ollama
except ImportError:
    print("ERROR: pip install ollama")
    exit(1)

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===

MODELS = [
    "qwen3:32b",                           # Qwen3 32B (20GB) - baseline
    "qwen3:30b-a3b",                       # Qwen3 30B MoE (19GB) - 30B total, 3B active
    "gpt-oss:20b",                         # OpenAI GPT-OSS 20B MoE (12GB) - 21B total, 3.6B active, reasoning
    "gemma3:27b-it-qat",                   # Gemma 3 27B IT-QAT (18GB)
]

TEMPERATURE = 0.3
MAX_TOKENS = 3000

# –í—ã–±–µ—Ä–µ–º 3 –≥–ª–∞–≤—ã —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
TEST_CHAPTERS = [
    {
        "file": "transcribe/–ë–æ–ª—å—à–æ–π –º–∞—Ä–∞—Ñ–æ–Ω –ø–æ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º—É AI. –î–µ–Ω—å 1._video_mp4_chapters.json",
        "packed": "transcribe/–ë–æ–ª—å—à–æ–π –º–∞—Ä–∞—Ñ–æ–Ω –ø–æ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º—É AI. –î–µ–Ω—å 1._video_mp4_packed.jsonl",
        "chapter_idx": 0,  # –ì–ª–∞–≤–∞ 1 - –¥–ª–∏–Ω–Ω–∞—è, –º–Ω–æ–≥–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞
        "name": "–î–µ–Ω—å 1, –ì–ª–∞–≤–∞ 1 (–¥–ª–∏–Ω–Ω–∞—è, ~7800 —Å–∏–º–≤–æ–ª–æ–≤)"
    },
    {
        "file": "transcribe/–ë–æ–ª—å—à–æ–π –º–∞—Ä–∞—Ñ–æ–Ω –ø–æ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º—É AI. –î–µ–Ω—å 2._video_mp4_chapters.json",
        "packed": "transcribe/–ë–æ–ª—å—à–æ–π –º–∞—Ä–∞—Ñ–æ–Ω –ø–æ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º—É AI. –î–µ–Ω—å 2._video_mp4_packed.jsonl",
        "chapter_idx": 5,  # –ì–ª–∞–≤–∞ 6 - —Å—Ä–µ–¥–Ω—è—è
        "name": "–î–µ–Ω—å 2, –ì–ª–∞–≤–∞ 6 (—Å—Ä–µ–¥–Ω—è—è, ~3500 —Å–∏–º–≤–æ–ª–æ–≤)"
    },
    {
        "file": "transcribe/–ë–æ–ª—å—à–æ–π –º–∞—Ä–∞—Ñ–æ–Ω –ø–æ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º—É AI. –î–µ–Ω—å 3_video_mp4_chapters.json",
        "packed": "transcribe/–ë–æ–ª—å—à–æ–π –º–∞—Ä–∞—Ñ–æ–Ω –ø–æ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º—É AI. –î–µ–Ω—å 3_video_mp4_packed.jsonl",
        "chapter_idx": 2,  # –ì–ª–∞–≤–∞ 3 - –∫–æ—Ä–æ—Ç–∫–∞—è
        "name": "–î–µ–Ω—å 3, –ì–ª–∞–≤–∞ 3 (–∫–æ—Ä–æ—Ç–∫–∞—è, ~2000 —Å–∏–º–≤–æ–ª–æ–≤)"
    }
]

# === –ü—Ä–æ–º–ø—Ç (–∏–¥–µ–Ω—Ç–∏—á–Ω—ã–π –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π) ===

SYSTEM_PROMPT = "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –¢—ã —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—à—å—Å—è –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ª–µ–∫—Ü–∏–π."

def build_prompt(chapter_title: str, chapter_text: str) -> str:
    """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM."""
    return f"""–¢—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ-–∫–æ–Ω—Ç–µ–Ω—Ç–∞.

**–ó–∞–¥–∞—á–∞:** —É–ª—É—á—à–∏—Ç—å —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —ç—Ç–æ–π –≥–ª–∞–≤—ã –≤–∏–¥–µ–æ-–ª–µ–∫—Ü–∏–∏.

**–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:**
‚úì –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏:
  ‚Ä¢ "–ü—ã–¢–æ—Ä—á" / "–ø–∞–π—Ç–æ—Ä—á" ‚Üí "PyTorch"
  ‚Ä¢ "–¥–∂–∏–ø–∏—Ç–∏" / "GPT-—à–∫–∞" ‚Üí "GPT"
  ‚Ä¢ "—Ç–µ–Ω–∑–æ—Ä—Ñ–ª–æ—É" ‚Üí "TensorFlow"
  ‚Ä¢ "–∫–µ—Ä–∞—Å" ‚Üí "Keras"
  ‚Ä¢ "–Ω–∞–º–ø–∞–π" ‚Üí "NumPy"
  ‚Ä¢ "–ø–∞–Ω–¥–∞—Å" ‚Üí "Pandas"
  ‚Ä¢ "–¥–∂—É–ø–∏—Ç–µ—Ä" ‚Üí "Jupyter"
  ‚Ä¢ "–∫–æ–ª–∞–±" ‚Üí "Colab"

‚úì –ö–†–ò–¢–ò–ß–ù–û: –£–±–µ—Ä–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!
  ‚Ä¢ –ï—Å–ª–∏ —Ñ—Ä–∞–∑–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è 3+ —Ä–∞–∑–∞ –ø–æ–¥—Ä—è–¥ ‚Äî –æ—Å—Ç–∞–≤—å –û–î–ù–£!
  ‚Ä¢ –ü—Ä–∏–º–µ—Ä –ü–õ–û–•–û: "–ü–æ–ª—É–æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º. –ü–æ–ª—É–æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º. –ü–æ–ª—É–æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º."
  ‚Ä¢ –ü—Ä–∏–º–µ—Ä –•–û–†–û–®–û: "–ü–æ–ª—É–æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º."

‚úì –£–±–µ—Ä–∏ —Ä–µ—á–µ–≤—ã–µ –ø–æ–≤—Ç–æ—Ä—ã –∏ "–≤–æ–¥—É" (–∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –≤–≤–æ–¥–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –∑–∞–∏–∫–∞–Ω–∏—è)
‚úì –°–æ—Ö—Ä–∞–Ω–∏ –í–°–ï —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, —Ç–µ—Ä–º–∏–Ω—ã, –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π, –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞
‚úì –°–æ—Ö—Ä–∞–Ω–∏ –í–°–ï —Å–º—ã—Å–ª–æ–≤—ã–µ –∏–¥–µ–∏, –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
‚úì –°–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç —Å–≤—è–∑–Ω—ã–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º (–ª–æ–≥–∏—á–Ω—ã–µ –∞–±–∑–∞—Ü—ã)
‚úì –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç–∏–ª—å —É—Å—Ç–Ω–æ–π —Ä–µ—á–∏ –ª–µ–∫—Ç–æ—Ä–∞ (–Ω–µ –¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–º)

**–ú–ò–ù–ò–ú–ò–ó–ò–†–£–ô –∏–ª–∏ –£–ë–ï–†–ò:**
‚úó –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã ("–ª—É—á—à–∏–π –∫—É—Ä—Å", "—É–Ω–∏–∫–∞–ª—å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å", "—É—Å–ø–µ–π –∫—É–ø–∏—Ç—å")
‚úó –ü—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é –Ω–µ –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –æ–±—É—á–µ–Ω–∏—é ("–ø–æ–¥–ø–∏—à–∏—Å—å", "–ø–æ—Å—Ç–∞–≤—å –ª–∞–π–∫")
‚úó –ò–∑–±—ã—Ç–æ—á–Ω—ã–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –ø—Ä–æ—â–∞–Ω–∏—è (–æ—Å—Ç–∞–≤—å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü)

**–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –°–û–•–†–ê–ù–ò:**
‚Ä¢ –í—Å–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏
‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥, –∫–æ–¥–∞, –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
‚Ä¢ –û–±—ä—è—Å–Ω–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
‚Ä¢ –õ–æ–≥–∏–∫—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—é
‚Ä¢ –°—Å—ã–ª–∫–∏ –Ω–∞ —Ä–µ—Å—É—Ä—Å—ã, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
‚Ä¢ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
‚Ä¢ –ß–∏—Å–ª–∞, –º–µ—Ç—Ä–∏–∫–∏, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

**–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞:**
–°–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç, —Ä–∞–∑–±–∏—Ç—ã–π –Ω–∞ –∞–±–∑–∞—Ü—ã. –ù–µ –¥–æ–±–∞–≤–ª—è–π –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏–ª–∏ —Ä–∞–∑–º–µ—Ç–∫–∏ - —Ç–æ–ª—å–∫–æ —É–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç.

**–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã "{chapter_title}":**

{chapter_text}

**–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è:**"""


def load_chapter_text(chapter_info: dict) -> tuple[str, str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã –∏–∑ —Ñ–∞–π–ª–æ–≤."""
    chapters_file = Path(chapter_info["file"])
    packed_file = Path(chapter_info["packed"])

    with chapters_file.open("r", encoding="utf-8") as f:
        data = json.load(f)

    chapter = data["chapters"][chapter_info["chapter_idx"]]

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–±–∑–∞—Ü—ã
    paragraphs = {}
    with packed_file.open("r", encoding="utf-8") as f:
        for line in f:
            row = json.loads(line.strip())
            if row.get("type") == "paragraph":
                paragraphs[row["id"]] = row["text"]

    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç
    chapter_text = "\n\n".join(
        paragraphs[pid] for pid in chapter["paragraph_ids"] if pid in paragraphs
    )

    return chapter["title"], chapter_text


def test_model(model_name: str, chapter_title: str, chapter_text: str) -> dict:
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–¥–Ω—É –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–π –≥–ª–∞–≤–µ."""
    print(f"\n{'='*80}")
    print(f"–ú–æ–¥–µ–ª—å: {model_name}")
    print(f"–ì–ª–∞–≤–∞: {chapter_title}")
    print(f"–ò—Å—Ö–æ–¥–Ω–∞—è –¥–ª–∏–Ω–∞: {len(chapter_text)} —Å–∏–º–≤–æ–ª–æ–≤")

    prompt = build_prompt(chapter_title, chapter_text)

    start_time = time.time()

    try:
        response = ollama.chat(
            model=model_name,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            options={
                "temperature": TEMPERATURE,
                "num_predict": MAX_TOKENS
            },
            think=False
        )

        edited_text = response['message']['content'].strip()
        elapsed_time = time.time() - start_time

        compression_ratio = len(edited_text) / len(chapter_text)

        print(f"[OK] –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
        print(f"  –í—Ä–µ–º—è: {elapsed_time:.2f} —Å–µ–∫")
        print(f"  –ù–æ–≤–∞—è –¥–ª–∏–Ω–∞: {len(edited_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  –ö–æ–º–ø—Ä–µ—Å—Å–∏—è: {compression_ratio:.2%} (—É–¥–∞–ª–µ–Ω–æ {(1-compression_ratio)*100:.1f}%)")

        return {
            "model": model_name,
            "chapter": chapter_title,
            "success": True,
            "time": round(elapsed_time, 2),
            "original_length": len(chapter_text),
            "edited_length": len(edited_text),
            "compression_ratio": round(compression_ratio, 4),
            "edited_text": edited_text,
            "error": None
        }

    except Exception as e:
        elapsed_time = time.time() - start_time
        print(f"[ERROR] –û–®–ò–ë–ö–ê: {e}")

        return {
            "model": model_name,
            "chapter": chapter_title,
            "success": False,
            "time": round(elapsed_time, 2),
            "original_length": len(chapter_text),
            "edited_length": 0,
            "compression_ratio": 0,
            "edited_text": "",
            "error": str(e)
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    print("=== –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM-–º–æ–¥–µ–ª–µ–π ===")
    print(f"–ú–æ–¥–µ–ª–µ–π: {len(MODELS)}")
    print(f"–¢–µ—Å—Ç–æ–≤—ã—Ö –≥–ª–∞–≤: {len(TEST_CHAPTERS)}")
    print(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {len(MODELS) * len(TEST_CHAPTERS)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π
    print("\n=== –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π ===")
    available_models = ollama.list()
    model_names = [m.model for m in available_models.models]

    for model in MODELS:
        # Ollama –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∏–º–µ–Ω–∞ —Å —Ç–µ–≥–∞–º–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        found = any(model in name or name.startswith(model.split(':')[0]) for name in model_names)
        status = "[OK]" if found else "[–ù–ï –ù–ê–ô–î–ï–ù–ê]"
        print(f"  {model}: {status}")

    print("\n=== –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ===\n")

    results = []

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    for chapter_info in TEST_CHAPTERS:
        print(f"\n{'#'*80}")
        print(f"# {chapter_info['name']}")
        print(f"{'#'*80}")

        chapter_title, chapter_text = load_chapter_text(chapter_info)

        for model in MODELS:
            result = test_model(model, chapter_title, chapter_text)
            results.append(result)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Ä—É—á–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            if result["success"]:
                output_file = Path(f"test_results/{model.replace(':', '_')}_{chapter_info['chapter_idx']}.txt")
                output_file.parent.mkdir(exist_ok=True)
                output_file.write_text(result["edited_text"], encoding="utf-8")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = Path(f"test_results/comparison_report_{timestamp}.json")
    report_file.parent.mkdir(exist_ok=True)

    with report_file.open("w", encoding="utf-8") as f:
        json.dump({
            "timestamp": timestamp,
            "models": MODELS,
            "test_chapters": [c["name"] for c in TEST_CHAPTERS],
            "parameters": {
                "temperature": TEMPERATURE,
                "max_tokens": MAX_TOKENS
            },
            "results": results
        }, f, indent=2, ensure_ascii=False)

    # –ü–µ—á–∞—Ç–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
    print(f"\n{'='*80}")
    print("üìä –ò–¢–û–ì–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê")
    print(f"{'='*80}\n")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–æ–¥–µ–ª—è–º
    for model in MODELS:
        model_results = [r for r in results if r["model"] == model]
        successful = [r for r in model_results if r["success"]]

        if not successful:
            print(f"[FAILED] {model}: –í–°–ï –¢–ï–°–¢–´ –ü–†–û–í–ê–õ–ï–ù–´")
            continue

        avg_time = sum(r["time"] for r in successful) / len(successful)
        avg_compression = sum(r["compression_ratio"] for r in successful) / len(successful)

        print(f"[OK] {model}")
        print(f"  –£—Å–ø–µ—à–Ω–æ: {len(successful)}/{len(model_results)}")
        print(f"  –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {avg_time:.2f} —Å–µ–∫/–≥–ª–∞–≤–∞")
        print(f"  –°—Ä–µ–¥–Ω—è—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è: {avg_compression:.2%} (—É–¥–∞–ª–µ–Ω–æ {(1-avg_compression)*100:.1f}%)")
        print()

    print(f"\n[REPORT] –ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_file}")
    print(f"[FILES] –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã: test_results/")
    print("\n=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! ===")


if __name__ == "__main__":
    main()
