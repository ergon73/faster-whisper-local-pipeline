# Обучение с подкреплением: настройка среды и моделей

Когда вы учитесь в институте, а посреди лекции жжёте пирожок — это настоящий пример обучения с подкреплением. Немного бредового юмора, но идея понятна: агент получает награду за правильные действия и штраф за неправильные. Именно так и работает обучение с подкреплением (Reinforcement Learning, RL).

В этой статье мы разберём, как настроить среду и обучить модель с помощью популярных библиотек, таких как `PyTorch`, `Stable Baselines3`, и `TensorBoard`. Мы будем использовать готовую среду `HighwayEnv` и сравним три алгоритма: `DQN`, `PPO` и `A2C`.

---

## Готовые среды для RL

Сегодня существует множество готовых сред для обучения с подкреплением. Например, `OpenAI Gym`, `Gymnasium`, `HighwayEnv`, и другие. Эти среды позволяют модели взаимодействовать с виртуальным миром, получать награды и штрафы, и обучаться на основе этого.

В нашем случае мы будем использовать `HighwayEnv`, где агент — это автомобиль, который должен ехать по дороге, избегая столкновений и стараясь развивать скорость. Пример настройки: