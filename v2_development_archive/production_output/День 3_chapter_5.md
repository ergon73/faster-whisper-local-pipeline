# Активационные функции и примеры работы нейронов

Нейросети — это мощный инструмент, но чтобы понять, как они работают, нужно разобраться с базовыми элементами: нейронами и активационными функциями. В этой статье мы рассмотрим, как нейроны обрабатывают входные данные и как они могут применяться на практике.

---

## Что такое активационная функция?

Активационная функция — это функция, которая определяет, как нейрон "реагирует" на входные сигналы. То есть, она преобразует сумму взвешенных входов в выходное значение.

### Примеры активационных функций

- **ReLU (Rectified Linear Unit)**:  
  - При отрицательных значениях возвращает 0.
  - При положительных — возвращает само значение.
  - Простая и эффективная функция, часто используется в современных нейросетях.

- **Сигмоида (Sigmoid)**:  
  - Гиперболический тангенс, сжатый в диапазон от 0 до 1.
  - При отрицательных значениях стремится к 0, при положительных — к 1.
  - Использовалась в ранних нейросетях, но сейчас уступает ReLU по скорости обучения.

- **Гиперболический тангенс (tanh)**:  
  - Диапазон от -1 до 1.
  - Также часто применяется, но менее популярна, чем ReLU.

**Важно:** выбор активационной функции влияет на способность сети "обучаться" и обобщать данные.

---

## Пример 1: Нейрон для прогноза погоды

Представьте, что вы хотите создать нейрон, который будет определять, растет ли температура или падает. У нейрона три входа: температура за сегодня, вчера и позавчера.

### Входы:
- Сегодня: 20°C
- Вчера: 18°C
- Позавчера: 15°C

### Веса (коэффициенты):
- Сегодня: 2
- Вчера: 1
- Позавчера: -3

### Расчёт: