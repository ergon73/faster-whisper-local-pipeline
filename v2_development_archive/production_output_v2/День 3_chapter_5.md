# Активационные функции и примеры работы нейронов

Нейросети — это мощный инструмент машинного обучения, основанный на имитации работы биологических нейронов. В этой статье мы разберем, как устроены нейроны, какие активационные функции используются, и как они помогают модели принимать решения. Мы также рассмотрим простые примеры, которые помогут понять, как нейросети обрабатывают входные данные и ищут в них признаки.

## Активационные функции: зачем они нужны?

Каждый нейрон в нейросети получает на вход набор чисел, умножает их на веса, суммирует и затем применяет активационную функцию. Эта функция определяет, каким будет выход нейрона — активным или неактивным.

### Примеры активационных функций

- **ReLU (Rectified Linear Unit)**:  
  - При отрицательных значениях возвращает 0.  
  - При положительных значениях возвращает само значение.  
  - Это одна из самых популярных функций, благодаря своей простоте и эффективности.

- **Сигмоида**:  
  - Преобразует любое число в диапазон от 0 до 1.  
  - Часто используется в задачах классификации.  
  - Формула: $ \sigma(x) = \frac{1}{1 + e^{-x}} $

- **Гиперболический тангенс (tanh)**:  
  - Преобразует числа в диапазон от -1 до 1.  
  - Также используется в задачах классификации.  
  - Формула: $ \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $

Каждая из этих функций имеет свои преимущества и недостатки, и выбор зависит от конкретной задачи и архитектуры сети.

## Пример 1: нейрон для прогноза погоды

Представим, что мы хотим создать нейрон, который будет определять, растет ли температура или падает. У нас есть три входа: температура за последние три дня — сегодня, вчера и позавчера.

Мы задаем веса:
- Позавчера: -3
- Вчера: 1
- Сегодня: 2

Эти веса мы подобрали "с потолка", но в реальности нейросеть сама их оптимизирует в процессе обучения.

Если температура растет, то:
- Сегодня: 18°C
- Вчера: 17°C
- Позавчера: 15°C

Рассчитаем выход нейрона: