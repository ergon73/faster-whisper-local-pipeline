# Обучение модели распознавания сущностей: от разметки к кластеризации

В этой статье мы рассмотрим, как можно обучить небольшую модель распознавания сущностей (NER — Named Entity Recognition) на реальных примерах, а также как провести кластеризацию текстов с помощью лемматизации и модели обработки естественного языка. Материал будет полезен Junior и Middle разработчикам, желающим понять, как применять NLP в реальных задачах.

---

## Что такое распознавание сущностей?

**NER (Named Entity Recognition)** — это задача из области обработки естественного языка, в которой модель должна определить и классифицировать именованные сущности в тексте. Например, в предложении:

> "Мы едем в Москву 5 декабря, возвращаемся 7 декабря."

Модель должна распознать:

- `Москва` — `location`
- `Краснодар` — `location`
- `5 декабря` — `date`
- `7 декабря` — `return date`

---

## Подготовка данных: разметка текста

Первым шагом в обучении модели является **разметка данных**. В данном случае разметка проводится **посимвольно**. Например, фраза `to` может быть размечена как `to`, а `Москва` — как `location`.

Пример разметки:

- Символы с 31 по 32 → `to`
- Символы с 33 по 39 → `location` (Москва)

Таким образом, модель получает понимание, где в тексте находятся ключевые сущности.

---

## Обучение модели

Модель обучается на **50 примерах**, включающих разные сценарии: путешествия с детьми, с животными, с собаками и т.д. Это позволяет ей обобщать и распознавать сущности даже в новых, неизвестных фразах.

> **Интересный факт:** даже если в обучающих данных не было упоминания хомяков, модель после обучения способна распознавать их как животных.

Пример обучающего текста:

> "Нужны билеты на самый быстрый поезд в Москву из Краснодара. Вечером 5 декабря. Нас четверо. Возвращаемся 7 декабря. С ребенком и собакой."

Результат разметки:

- `Сбербанк` — `organization`
- `билеты` — `comfort`
- `Москва` — `location`
- `Краснодар` — `location`
- `5 декабря` — `date`
- `7 декабря` — `return date`
- `ребенок` — `child`
- `собака` — `animal`

---

## Почему это работает?

- **Малое количество данных.** Для обучения требуется всего 50 примеров.
- **Высокая скорость работы.** Модель работает быстрее, чем LLM (например, GPT), что критично для обработки звонков в реальном времени.
- **Независимость от LLM.** Не требуется подключение к GPT или другим моделям, что важно для госкомпаний.
- **Низкие ресурсные требования.** Нет необходимости в мощных видеокартах.

---

## Применение в реальных проектах

Такие модели уже применяются в Сбербанке и других крупных компаниях. Например, в звонках клиентов автоматически определяются:

- Улицы
- Организации
- Имена и фамилии
- Типы врачей
- Даты и времена

Это позволяет автоматизировать обработку обращений, ускорить обработку данных и снизить нагрузку на операторов.

---

## Кластеризация текстов: пример с Genzyme и Pymorphic

Второй пример касается **кластеризации текстов**. Представьте, что у нас есть корпус текстов, в котором есть фразы на три темы:

1. NLP
2. Компьютерное зрение
3. Временные ряды

Мы хотим разделить эти фразы на три кластера, не указывая модельке, как это сделать.

### Шаги:

1. **Лемматизация текста**  
   Приведение слов к нормальной форме. Например:

   - `бегал`, `бежал`, `бегать` → `бегать`
   - `собака`, `собакой`, `собаке` → `собака`

   Это помогает алгоритму понять, что разные формы одного слова — это на самом деле одно и то же слово.

2. **Кластеризация**  
   С помощью модели (например, из библиотеки `Genzyme`) тексты разделяются на три кластера. Модель должна увидеть, что:

   - Одни тексты говорят про NLP
   - Другие — про компьютерное зрение
   - Третьи — про временные ряды

3. **Результат**  
   Модель действительно способна выделить устойчивые кластеры, даже если тексты поданы в перемешку.

---

## Заключение

- **Модель NER** может быть обучена на небольшом количестве примеров и с высокой точностью распознавать сущности.
- **Кластеризация текстов** с помощью лемматизации и модели позволяет группировать тексты по темам.
- Такие подходы находят применение в реальных проектах: от обработки звонков до анализа обращений в техподдержку.

Если вы хотите применить эти методы в своем проекте, можно интегрировать модель в приложение, выложить ее на веб-сервис и создать API. Это особенно полезно для госорганов, которым сложно использовать LLM.

---

**P.S.** Как отметил спикер, вебинары — это не только обучение для аудитории, но и для самого докладчика. Каждый раз — новые открытия, новые идеи и новые возможности для применения машинного обучения в реальном мире.