# Обучение с подкреплением: A2C и трейдинг на реальных акциях

В этой статье мы рассмотрим применение алгоритма **A2C (Advantage Actor-Critic)** в задаче обучения с подкреплением. Мы разберем, как он может быть использован для трейдинга на реальных акциях, и сравним его с другими популярными алгоритмами, такими как **DDPG**, **PPO**, **TD3** и **SAC**.

---

## Что такое A2C?

**A2C** — это алгоритм обучения с подкреплением, который объединяет в себе идеи **Actor-Critic** подхода. В отличие от более простых методов, A2C использует параллельные среды для ускорения обучения и повышения стабильности.

### Как это работает?

- **Actor** — это политика, которая определяет, какие действия предпринимать.
- **Critic** — оценивает, насколько хороша была выбранная политика, на основе полученных **reward'ов**.
- Алгоритм использует **Advantage Function**, которая показывает, насколько лучше выбранное действие по сравнению со средним.

---

## Пример: обучение модели открывать дверь

Для наглядности спикер привел пример обучения модели открывать дверь. Модель не знала, что такое дверь, и не получала никаких инструкций. Ей просто давали **репорды** (reward'ы) за успешные действия и **антирепорды** за ошибки.

- Обучение происходило в виртуальной среде.
- Модель обучалась **400 тысяч итераций**.
- Результат: модель научилась открывать дверь без явного указания, как это делать.
- Это похоже на то, как **DeepMind** обучал **AlphaGo** и **AlphaStar**.

> **Жирный вывод:** Обучение с подкреплением позволяет модели "думать" и принимать решения, основываясь только на получаемых наградах, без явного программирования логики.

---

## Применение A2C в трейдинге

Теперь перейдем к более сложной задаче — трейдингу на реальных акциях.

### Подготовка данных

Спикер использовал данные по 10 крупным акциям:

- Apple
- Microsoft
- Google
- Amazon
- Coca-Cola
- American Express
- Chevron
- IBM
- McDonald's
- Walmart

Данные брались с 2010 по 2021 год для обучения и с 2021 по 2024 год для тестирования.

> Использовался инструмент `Yahoo Finance` для загрузки данных.

### Предобработка данных

- Добавлялись дополнительные **трейдинговые индикаторы**, такие как:
  - Средние скользящие
  - Индекс волатильности
  - MACD
  - RSI
- Все это помогло модели лучше понимать динамику цен.

> **Важно:** Все индикаторы были взяты из общедоступных источников и подсказок от `GPT`.

---

## Создание трейдинговой среды

Спикер использовал специальную среду для трейдинга, которая имитирует реальный рынок.

### Параметры среды:

- Начальный капитал: **100 млн $**
- Максимальное количество акций на одну сделку
- Комиссия: **0.1%**
- Количество акций: **10**
- Использовались **трейдинговые индикаторы** для оценки состояния рынка

---

## Обучение и тестирование

Было запущено обучение **A2C**, **DDPG**, **PPO**, **TD3**, **SAC** на **50 тысяч трасс**.

### Результаты:

- **A2C** показал **лучший результат**:
  - За 3 года (2021–2024) вырос на **+28.43%**
  - В 2022 году был просадок (коронавирус), но потом восстановился
  - Модель выбрала акции: **Amazon, IBM, McDonald's, Microsoft**
  - Продала Microsoft и Amazon, докупила IBM, Google, McDonald's и немного Walmart

- **DDPG**:
  - Результат: **+12.5%**
  - Купил Apple, CVX, American Express, Google, IBM, Coca-Cola
  - Проседал в 2022 году, но выровнялся

> **Вывод:** A2C оказался более устойчивым и эффективным в этой задаче.

---

## Почему A2C сработал лучше?

- A2C — это **высокоуровневый алгоритм**, который учится на основе наград.
- Он не требует явного программирования логики.
- В задаче трейдинга он смог адаптироваться к изменению рынка и выбрать прибыльные акции.

---

## Заключение

Обучение с подкреплением — это мощный инструмент, который может применяться не только в робототехнике, но и в финансах. В этой статье мы увидели, как алгоритм **A2C** может быть использован для трейдинга на реальных акциях и почему он оказался более эффективным, чем другие алгоритмы.

### Что дальше?

- Можно попробовать обучать модель дольше
- Добавить больше индикаторов
- Использовать **нейросети** с большей глубиной
- Попробовать **обучение с подкреплением в реальном времени**

---

> **Главный посыл:** Обучение с подкреплением — это не магия. Это мощный инструмент, который требует правильной настройки, данных и времени. Но результаты могут быть потрясающими.