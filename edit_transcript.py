"""–≠—Ç–∞–ø 2.5: LLM-—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤ - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫, —É–¥–∞–ª–µ–Ω–∏–µ '–≤–æ–¥—ã', –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.

Production v2 (Enhanced Prompt): –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å fallback-–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π
–¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–ª–æ—Ç–Ω–æ–≥–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–ò–∑–º–µ–Ω–µ–Ω–∏—è v2:
- –ü—Ä–æ–º–ø—Ç –≤ —Å—Ç–∏–ª–µ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ –•–∞–±—Ä–∞ (Habr editor style)
- Fallback-–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è Dense Technical Content Without Context
- Regex –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è <think> —Ç–µ–≥–æ–≤ –∏ markdown-–æ–±–µ—Ä—Ç–æ–∫
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–Ω–æ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–æ–π –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ (<10%)
- –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: repeat_penalty=1.1, top_k=40, num_ctx=8192

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (65 –≥–ª–∞–≤):
- –ê–Ω–æ–º–∞–ª–∏–∏ —Å–Ω–∏–∂–µ–Ω—ã —Å 9.2% –¥–æ 3.1%
- 96.9% –≥–ª–∞–≤ —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
- –°—Ä–µ–¥–Ω—è—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è: 52.65%
"""

from __future__ import annotations

import json
import logging
import os
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional

try:
    from dotenv import load_dotenv  # type: ignore
except Exception:
    load_dotenv = None

try:
    import ollama
except ImportError:
    print("ERROR: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ollama: pip install ollama")
    sys.exit(1)

DEFAULT_TRANSCRIBE_OUT = "transcribe"

def getenv_str(key: str, default: str) -> str:
    v = os.getenv(key)
    return v if v is not None and v.strip() else default

def getenv_int(key: str, default: int) -> int:
    try:
        return int(os.getenv(key, str(default)))
    except Exception:
        return default

def getenv_float(key: str, default: float) -> float:
    try:
        return float(os.getenv(key, str(default)))
    except Exception:
        return default

def getenv_bool(key: str, default: bool) -> bool:
    v = os.getenv(key)
    if v is None: return default
    return v.strip().lower() in {"1","true","yes","y","on"}

@dataclass
class Chapter:
    """–ì–ª–∞–≤–∞ –∏–∑ chapters.json."""
    id: int
    title: str
    start: Optional[float]
    end: Optional[float]
    paragraph_ids: List[int]
    text: str  # –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

@dataclass
class EditedChapter:
    """–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–ª–∞–≤–∞."""
    id: int
    title: str
    start: Optional[float]
    end: Optional[float]
    original_text: str
    edited_text: str
    original_length: int
    edited_length: int
    compression_ratio: float

def read_chapters_json(path: Path) -> tuple[dict, list[Chapter]]:
    """–ß–∏—Ç–∞–µ—Ç chapters.json –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ –≥–ª–∞–≤—ã."""
    with path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    meta = data.get("metadata", {})
    chapters: List[Chapter] = []

    for ch in data.get("chapters", []):
        chapters.append(Chapter(
            id=ch["id"],
            title=ch["title"],
            start=ch.get("start"),
            end=ch.get("end"),
            paragraph_ids=ch.get("paragraph_ids", []),
            text=""  # –ó–∞–ø–æ–ª–Ω–∏–º –ø–æ–∑–∂–µ –∏–∑ packed.jsonl
        ))

    return meta, chapters

def read_packed_jsonl(path: Path) -> dict[int, str]:
    """–ß–∏—Ç–∞–µ—Ç packed.jsonl –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {paragraph_id: text}."""
    paragraphs = {}

    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line: continue

            try:
                row = json.loads(line)
            except Exception:
                continue

            if row.get("type") == "paragraph":
                para_id = row.get("id")
                text = row.get("text", "")
                if para_id is not None:
                    paragraphs[para_id] = text

    return paragraphs

def fill_chapter_texts(chapters: List[Chapter], paragraphs: dict[int, str]) -> None:
    """–ó–∞–ø–æ–ª–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç –≥–ª–∞–≤ –∏–∑ —Å–ª–æ–≤–∞—Ä—è –∞–±–∑–∞—Ü–µ–≤."""
    for chapter in chapters:
        texts = []
        for para_id in chapter.paragraph_ids:
            if para_id in paragraphs:
                texts.append(paragraphs[para_id])
        chapter.text = "\n\n".join(texts)

def build_prompt_balanced_v2(chapter_title: str, chapter_text: str) -> str:
    """–ü—Ä–æ–º–ø—Ç –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (—Ä–µ–¥–∞–∫—Ç–æ—Ä –•–∞–±—Ä–∞) + fallback –¥–ª—è –ø–ª–æ—Ç–Ω–æ–π —Ç–µ—Ö–Ω–∏–∫–∏.

    Production v2 (Enhanced): –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    –Ω–∞ –ø–ª–æ—Ç–Ω–æ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º –∫–æ–Ω—Ç–µ–Ω—Ç–µ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    """
    return f"""–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –±–ª–æ–≥–∞ –Ω–∞ –•–∞–±—Ä–µ.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –¥–æ–∫–ª–∞–¥–∞ –≤ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—É—é, —á–∏—Ç–∞–µ–º—É—é —Å—Ç–∞—Ç—å—é.

**–¢–í–û–Ø –¶–ï–õ–¨:**
–°–¥–µ–ª–∞—Ç—å —Ç–µ–∫—Å—Ç –ø–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è Junior/Middle —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –≥–ª—É–±–∏–Ω—É –º–∞—Ç–µ—Ä–∏–∞–ª–∞.

**–ò–ù–°–¢–†–£–ö–¶–ò–ò:**
1. **–¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–Ø:**
   - –ò—Å–ø—Ä–∞–≤–ª—è–π –æ—à–∏–±–∫–∏ STT: "–ø–∞–π—Ç–æ—Ä—á" -> `PyTorch`, "–¥–∂–∏–ø–∏—Ç–∏" -> `GPT`, "–ø–∞–Ω–¥–∞—Å" -> `Pandas`.
   - –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–µ–≥–∏—Å—Ç—Ä –¥–ª—è –±–∏–±–ª–∏–æ—Ç–µ–∫ (–Ω–µ numpy, –∞ `NumPy`).
   - –ö–æ–¥ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫ –æ–±–æ—Ä–∞—á–∏–≤–∞–π –≤ –æ–±—Ä–∞—Ç–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ (`code`).

2. **–°–¢–ò–õ–¨ –ò –°–¢–†–£–ö–¢–£–†–ê:**
   - –†–∞–∑–±–µ–π —Ç–µ–∫—Å—Ç –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å–µ–∫—Ü–∏–∏ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ (##, ###).
   - –ï—Å–ª–∏ —Å–ø–∏–∫–µ—Ä –ø—Ä–∏–≤–æ–¥–∏—Ç –ø—Ä–∏–º–µ—Ä –∏–ª–∏ –º–µ—Ç–∞—Ñ–æ—Ä—É ‚Äî **—Å–æ—Ö—Ä–∞–Ω–∏ –µ—ë**, —ç—Ç–æ –¥–µ–ª–∞–µ—Ç —Ç–µ–∫—Å—Ç –∂–∏–≤—ã–º.
   - –ò–∑–±–µ–≥–∞–π –∫–∞–Ω—Ü–µ–ª—è—Ä–∏–∑–º–æ–≤. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç–æ –∏ –µ–º–∫–æ.
   - –£–±–∏—Ä–∞–π —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–π –º—É—Å–æ—Ä ("—ç-—ç-—ç", "—Å–ª—ã—à–Ω–æ –º–µ–Ω—è"), –Ω–æ –Ω–µ —Å—É—à–∏ —Ç–µ–∫—Å—Ç –¥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞.

3. **–§–û–†–ú–ê–¢:**
   - –¢–æ–ª—å–∫–æ Markdown.
   - –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏ –¥–ª—è –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–π.
   - –í–∞–∂–Ω—ã–µ –º—ã—Å–ª–∏ –≤—ã–¥–µ–ª—è–π **–∂–∏—Ä–Ω—ã–º**.

**–û–°–û–ë–´–ô –°–õ–£–ß–ê–ô (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ª–µ–∫—Ü–∏—è –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞):**
–ï—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ä–∞–∑—É –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –ø–ª–æ—Ç–Ω–æ–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏ –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è:
- –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ (1-2 –∞–±–∑–∞—Ü–∞), –æ–±—ä—è—Å–Ω—è—é—â–µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –º–∞—Ç–µ—Ä–∏–∞–ª –≤ –≤–∏–¥–µ –ø–æ—à–∞–≥–æ–≤–æ–≥–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –∏–ª–∏ —Å–ø–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
- –î–æ–±–∞–≤—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è –º–µ–∂–¥—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –±–ª–æ–∫–∞–º–∏
- –î–∞–∂–µ –µ—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—É—Ö–æ–π, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è —Å–¥–µ–ª–∞—Ç—å –µ–≥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —á–∏—Ç–∞–µ–º—ã–º

**–í–•–û–î–ù–û–ô –¢–ï–ö–°–¢:**
–¢–µ–º–∞: {chapter_title}
–¢–µ–∫—Å—Ç:
{chapter_text}

**–°–¢–ê–¢–¨–Ø (MARKDOWN):**"""


def clean_output(text: str) -> str:
    """–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å regex-–æ—á–∏—Å—Ç–∫–æ–π (—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞).

    1. –£–¥–∞–ª—è–µ—Ç <think>...</think> (–Ω–∞ —Å–ª—É—á–∞–π —Ñ–∏–ª–æ—Å–æ—Ñ—Å—Ç–≤–æ–≤–∞–Ω–∏—è)
    2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ Markdown-–æ–±–µ—Ä—Ç–∫–∏ (```markdown...```)
    """
    import re
    # 1. –£–¥–∞–ª—è–µ–º <think> —Ç–µ–≥–∏
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

    # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ Markdown-–æ–±–µ—Ä—Ç–∫–∏ (Qwen –ª—é–±–∏—Ç –æ–±–æ—Ä–∞—á–∏–≤–∞—Ç—å!)
    match = re.search(r'```(?:markdown)?\s*(.*?)```', text, re.DOTALL)
    if match:
        text = match.group(1).strip()

    return text.strip()


def edit_chapter_with_llm(
    chapter: Chapter,
    llm_model: str,
    temperature: float,
    max_tokens: int,
    logger: logging.Logger
) -> str:
    """–†–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç –≥–ª–∞–≤—É —á–µ—Ä–µ–∑ LLM (Production v2: Enhanced Prompt)."""

    prompt = build_prompt_balanced_v2(chapter.title, chapter.text)

    try:
        logger.info(f"–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–ª–∞–≤—ã {chapter.id}: ¬´{chapter.title}¬ª ({len(chapter.text)} —Å–∏–º–≤–æ–ª–æ–≤)...")

        start_time = time.time()

        response = ollama.chat(
            model=llm_model,
            messages=[
                {
                    "role": "system",
                    "content": "You are a professional technical blog editor. Output clean Markdown only."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            options={
                "temperature": temperature,
                "repeat_penalty": 1.1,  # Production v2: –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ
                "top_k": 40,
                "num_ctx": 8192,
                "num_predict": max_tokens
            },
            think=False
        )

        edited_text = response['message']['content'].strip()

        # Production v2: –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫—É (—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞ –æ—Ç <think> –∏ markdown-–æ–±–µ—Ä—Ç–∫–∏)
        edited_text = clean_output(edited_text)

        elapsed = time.time() - start_time

        logger.info(f"  –ì–æ—Ç–æ–≤–æ –∑–∞ {elapsed:.1f}—Å. –î–ª–∏–Ω–∞: {len(chapter.text)} ‚Üí {len(edited_text)} —Å–∏–º–≤–æ–ª–æ–≤")

        return edited_text

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –≥–ª–∞–≤—ã {chapter.id}: {e}")
        logger.warning(f"  –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≥–ª–∞–≤—ã {chapter.id}")
        return chapter.text

def validate_edited_text(
    original: str,
    edited: str,
    min_ratio: float,
    max_ratio: float,
    logger: logging.Logger,
    chapter_id: int
) -> tuple[bool, str]:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç.

    Returns: (is_valid, reason)
    """
    if not edited or not edited.strip():
        logger.warning(f"  –ì–ª–∞–≤–∞ {chapter_id}: –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return False, "empty"

    orig_len = len(original)
    edit_len = len(edited)
    ratio = edit_len / orig_len if orig_len > 0 else 0

    if ratio < min_ratio:
        logger.warning(f"  –ì–ª–∞–≤–∞ {chapter_id}: —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º —Å–æ–∫—Ä–∞—Ç–∏–ª—Å—è ({ratio:.2f} < {min_ratio})")
        return False, "too_short"

    if ratio > max_ratio:
        logger.warning(f"  –ì–ª–∞–≤–∞ {chapter_id}: —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º —É–≤–µ–ª–∏—á–∏–ª—Å—è ({ratio:.2f} > {max_ratio})")
        return False, "too_long"

    return True, "ok"

def write_edited_md(edited_chapters: List[EditedChapter], meta: dict, path: Path) -> None:
    """–°–æ–∑–¥–∞—ë—Ç edited markdown —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º."""
    with path.open("w", encoding="utf-8") as f:
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        f.write(f"# {meta.get('source_file', '–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç')} (–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)\n\n")

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if meta.get("duration"):
            duration_min = meta["duration"] / 60
            f.write(f"**–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {duration_min:.1f} –º–∏–Ω—É—Ç\n\n")

        f.write(f"**–ì–ª–∞–≤:** {len(edited_chapters)}\n\n")
        f.write("_–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω —Å –ø–æ–º–æ—â—å—é LLM-—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –û—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã, '–≤–æ–¥–∞' —É–¥–∞–ª–µ–Ω–∞, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω._\n\n")

        # –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
        f.write("## üìë –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ\n\n")
        for ch in edited_chapters:
            timestamp = ""
            if ch.start is not None:
                minutes = int(ch.start // 60)
                seconds = int(ch.start % 60)
                timestamp = f" `[{minutes:02d}:{seconds:02d}]`"

            f.write(f"{ch.id}. **{ch.title}**{timestamp}\n")

        f.write("\n---\n\n")

        # –¢–µ–∫—Å—Ç –ø–æ –≥–ª–∞–≤–∞–º
        for ch in edited_chapters:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã
            f.write(f"## –ì–ª–∞–≤–∞ {ch.id}: {ch.title}\n\n")

            # –¢–∞–π–º–∫–æ–¥
            if ch.start is not None and ch.end is not None:
                start_min = int(ch.start // 60)
                start_sec = int(ch.start % 60)
                end_min = int(ch.end // 60)
                end_sec = int(ch.end % 60)
                f.write(f"**–¢–∞–π–º–∫–æ–¥:** {start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}\n\n")

            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –¥–ª—è —Å–∏–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â—ë–Ω–Ω—ã—Ö –≥–ª–∞–≤
            if ch.compression_ratio < 0.5:
                reduction_pct = int((1 - ch.compression_ratio) * 100)
                f.write(f"> ‚ö†Ô∏è **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –≠—Ç–∞ –≥–ª–∞–≤–∞ –±—ã–ª–∞ —Å–∏–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∞ ({reduction_pct}% —É–¥–∞–ª–µ–Ω–æ). ")
                f.write("–ò—Å—Ö–æ–¥–Ω–∞—è –≥–ª–∞–≤–∞ —Å–æ–¥–µ—Ä–∂–∞–ª–∞ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –ø—Ä–∏–∑—ã–≤—ã, –ø–æ–≤—Ç–æ—Ä—ã –∏ –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –≤–≤–æ–¥–Ω—ã–µ —Ñ—Ä–∞–∑—ã.\n\n")

            # –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            f.write(ch.edited_text)
            f.write("\n\n---\n\n")

def write_report(report: dict, path: Path) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á—ë—Ç –æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏."""
    with path.open("w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

def main() -> None:
    """CLI-—Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è LLM-—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤."""
    if load_dotenv is not None: load_dotenv()

    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
    logger = logging.getLogger("edit_transcript")

    out_dir = Path(getenv_str("TRANSCRIBE_OUT", DEFAULT_TRANSCRIBE_OUT))
    if not out_dir.exists():
        logger.error("Directory not found: %s", out_dir)
        sys.exit(1)

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    cfg = {
        "llm_model": getenv_str("EDIT_LLM_MODEL", "qwen3:32b"),
        "temperature": getenv_float("EDIT_LLM_TEMPERATURE", 0.3),
        "max_tokens": getenv_int("EDIT_LLM_MAX_TOKENS", 3000),
        "min_length_ratio": getenv_float("EDIT_MIN_LENGTH_RATIO", 0.7),
        "max_length_ratio": getenv_float("EDIT_MAX_LENGTH_RATIO", 1.3),
        "write_report": getenv_bool("EDIT_REPORT", True),
        "dry_run": getenv_bool("EDIT_DRY_RUN", False)
    }

    logger.info("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: %s", cfg)

    if cfg["dry_run"]:
        logger.info("–†–ï–ñ–ò–ú DRY RUN - —Ñ–∞–π–ª—ã –Ω–µ –±—É–¥—É—Ç –∑–∞–ø–∏—Å–∞–Ω—ã")

    # –ù–∞–π—Ç–∏ –≤—Å–µ *_chapters.json —Ñ–∞–π–ª—ã
    chapters_files = list(out_dir.glob("*_chapters.json"))

    if not chapters_files:
        logger.warning("No *_chapters.json files found in %s", out_dir)
        return

    for chapters_file in sorted(chapters_files):
        logger.info("=" * 70)
        logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞: %s", chapters_file.name)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤–æ–µ –∏–º—è
        base_name = chapters_file.name.replace("_chapters.json", "")

        # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π packed.jsonl
        packed_file = out_dir / f"{base_name}_packed.jsonl"
        if not packed_file.exists():
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª %s, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", packed_file.name)
            continue

        # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        meta, chapters = read_chapters_json(chapters_file)
        paragraphs = read_packed_jsonl(packed_file)

        # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ç–µ–∫—Å—Ç –≥–ª–∞–≤
        fill_chapter_texts(chapters, paragraphs)

        logger.info("–ó–∞–≥—Ä—É–∂–µ–Ω–æ –≥–ª–∞–≤: %d", len(chapters))

        # –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –≥–ª–∞–≤—É
        edited_chapters: List[EditedChapter] = []
        total_original_length = 0
        total_edited_length = 0
        failed_validations = 0

        for chapter in chapters:
            if not chapter.text.strip():
                logger.warning(f"–ì–ª–∞–≤–∞ {chapter.id} –ø—É—Å—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            # –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º
            edited_text = edit_chapter_with_llm(
                chapter,
                llm_model=cfg["llm_model"],
                temperature=cfg["temperature"],
                max_tokens=cfg["max_tokens"],
                logger=logger
            )

            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            is_valid, reason = validate_edited_text(
                chapter.text,
                edited_text,
                cfg["min_length_ratio"],
                cfg["max_length_ratio"],
                logger,
                chapter.id
            )

            # –ï—Å–ª–∏ –Ω–µ –ø—Ä–æ—à–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏—é - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            if not is_valid:
                logger.warning(f"  –ì–ª–∞–≤–∞ {chapter.id}: –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞ ({reason}), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç")
                edited_text = chapter.text
                failed_validations += 1

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            orig_len = len(chapter.text)
            edit_len = len(edited_text)
            ratio = edit_len / orig_len if orig_len > 0 else 1.0

            # Production v2: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–Ω–æ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–æ–π –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏
            if ratio < 0.10:
                logger.warning(f"  ‚ö†Ô∏è –ì–ª–∞–≤–∞ {chapter.id}: —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è ({ratio:.2%}). –ú–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.")
            elif ratio < 0.15:
                logger.info(f"  ‚ÑπÔ∏è –ì–ª–∞–≤–∞ {chapter.id}: –Ω–∏–∑–∫–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è ({ratio:.2%}), –Ω–æ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ.")

            edited_chapters.append(EditedChapter(
                id=chapter.id,
                title=chapter.title,
                start=chapter.start,
                end=chapter.end,
                original_text=chapter.text,
                edited_text=edited_text,
                original_length=orig_len,
                edited_length=edit_len,
                compression_ratio=ratio
            ))

            total_original_length += orig_len
            total_edited_length += edit_len

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º–µ–Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        edited_md_path = out_dir / f"{base_name}_edited.md"
        report_path = out_dir / f"{base_name}_edit_report.json"

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if not cfg["dry_run"]:
            meta["source_file"] = chapters_file.name
            write_edited_md(edited_chapters, meta, edited_md_path)
            logger.info("‚úì –°–æ–∑–¥–∞–Ω–æ: %s", edited_md_path.name)

            # –û—Ç—á—ë—Ç
            if cfg["write_report"]:
                report = {
                    "source_chapters": chapters_file.name,
                    "total_chapters": len(edited_chapters),
                    "failed_validations": failed_validations,
                    "original_total_length": total_original_length,
                    "edited_total_length": total_edited_length,
                    "overall_compression_ratio": total_edited_length / total_original_length if total_original_length > 0 else 1.0,
                    "config": cfg,
                    "chapters_summary": [
                        {
                            "id": ch.id,
                            "title": ch.title,
                            "original_length": ch.original_length,
                            "edited_length": ch.edited_length,
                            "compression_ratio": ch.compression_ratio
                        }
                        for ch in edited_chapters
                    ]
                }
                write_report(report, report_path)
                logger.info("‚úì –°–æ–∑–¥–∞–Ω–æ: %s", report_path.name)

        logger.info("–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≥–ª–∞–≤: %d", len(edited_chapters))
        logger.info("–û–±—â–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è: %.2f (%.0f%% –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ)",
                   total_edited_length / total_original_length if total_original_length > 0 else 1.0,
                   100 * total_edited_length / total_original_length if total_original_length > 0 else 100)

if __name__ == "__main__":
    main()
